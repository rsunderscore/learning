{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boston_housing',\n",
       " 'cifar10',\n",
       " 'cifar100',\n",
       " 'fashion_mnist',\n",
       " 'imdb',\n",
       " 'mnist',\n",
       " 'reuters']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for x in dir(tf.keras.datasets) if '_' != x[0] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist\n",
    "#https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 28, 28)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   3,\n",
       "         18,  18,  18, 126, 136, 175,  26, 166, 255, 247, 127,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  30,  36,  94, 154, 170,\n",
       "        253, 253, 253, 253, 253, 225, 172, 253, 242, 195,  64,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  49, 238, 253, 253, 253, 253,\n",
       "        253, 253, 253, 253, 251,  93,  82,  82,  56,  39,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,  18, 219, 253, 253, 253, 253,\n",
       "        253, 198, 182, 247, 241,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  80, 156, 107, 253, 253,\n",
       "        205,  11,   0,  43, 154,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,  14,   1, 154, 253,\n",
       "         90,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0, 139, 253,\n",
       "        190,   2,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  11, 190,\n",
       "        253,  70,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  35,\n",
       "        241, 225, 160, 108,   1,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "         81, 240, 253, 253, 119,  25,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  45, 186, 253, 253, 150,  27,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,  16,  93, 252, 253, 187,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0, 249, 253, 249,  64,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,  46, 130, 183, 253, 253, 207,   2,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  39,\n",
       "        148, 229, 253, 253, 253, 250, 182,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,  24, 114, 221,\n",
       "        253, 253, 253, 253, 201,  78,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,  23,  66, 213, 253, 253,\n",
       "        253, 253, 198,  81,   2,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,  18, 171, 219, 253, 253, 253, 253,\n",
       "        195,  80,   9,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,  55, 172, 226, 253, 253, 253, 253, 244, 133,\n",
       "         11,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0, 136, 253, 253, 253, 212, 135, 132,  16,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0],\n",
       "       [  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "          0,   0]], dtype=uint8)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def display_digit(digit, title=''):\n",
    "    title = str(title)\n",
    "    title = 'label is {}'.format(title) if len(title)>0 else ''\n",
    "    plt.imshow(digit, cmap='Greys', interpolation='nearest')#no reshape needed?\n",
    "    plt.suptitle(title)\n",
    "    plt.colorbar()\n",
    "    \n",
    "def disp_tr_index(index):\n",
    "    display_digit(train_images[index], train_labels[index])\n",
    "    \n",
    "def disp_tst_index(index):\n",
    "    display_digit(test_images[index], test_labels[index])\n",
    "#display_digit(train_images[10])\n",
    "#print(train_labels[10])\n",
    "disp_tst_index(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([5, 0, 4, 1, 9], dtype=uint8)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "height=28\n",
    "width=28\n",
    "channels=1\n",
    "n_inputs = height * width"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings for first conv layer\n",
    "conv1_feature_maps=32 #32 feature maps in layer\n",
    "conv1_kernel_size = 3 #3x3 kernel\n",
    "conv1_stride=1 #horiz and vert\n",
    "conv1_pad = \"SAME\" # 0 pad to consider edges \n",
    "# or \"VALID\" to get no zero pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#settings for second conv layer\n",
    "conv2_feature_maps=64 # feature maps in layer\n",
    "conv2_kernel_size = 3 #3x3 kernel\n",
    "conv2_stride=2 #bigger stride\n",
    "conv2_pad = \"SAME\" # 0 pad to consider edges \n",
    "# or \"VALID\" to get no zero pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool3_feature_maps = conv2_feature_maps #same as last conv layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fullyconn1 = 64\n",
    "n_outputs = 10 #number of possible digit classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X = tf.placeholder(tf.float32, shape=[None, n_inputs], name='X')\n",
    "#y = tf.placeholder(tf.int32, shape=[None], name='y')\n",
    "#X = tf.compat.v1.placeholder(tf.float32, shape=[None, n_inputs], name='X')# tf.placeholder() is not compatible with eager execution.\n",
    "#dir(tf)\n",
    "#example is deprecated need to find newer way\n",
    "model = tf.keras.models.Sequential()\n",
    "#model.add(tf.keras.layers.Input(shape=(None,n_inputs), name='X'))    # keras processing layer - no neurons\n",
    "#https://www.tensorflow.org/guide/migrate\n",
    "\n",
    "#X = tf.Variable(dtype=tf.float32, shape=(None, n_inputs), name='X')#ValueError: initial_value must be specified.\n",
    "#tf.Tensor(shape=(None, n_inputs), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class Conv2D in module tensorflow.python.keras.layers.convolutional:\n",
      "\n",
      "class Conv2D(Conv)\n",
      " |  Conv2D(filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  2D convolution layer (e.g. spatial convolution over images).\n",
      " |  \n",
      " |  This layer creates a convolution kernel that is convolved\n",
      " |  with the layer input to produce a tensor of\n",
      " |  outputs. If `use_bias` is True,\n",
      " |  a bias vector is created and added to the outputs. Finally, if\n",
      " |  `activation` is not `None`, it is applied to the outputs as well.\n",
      " |  \n",
      " |  When using this layer as the first layer in a model,\n",
      " |  provide the keyword argument `input_shape`\n",
      " |  (tuple of integers, does not include the sample axis),\n",
      " |  e.g. `input_shape=(128, 128, 3)` for 128x128 RGB pictures\n",
      " |  in `data_format=\"channels_last\"`.\n",
      " |  \n",
      " |  Arguments:\n",
      " |    filters: Integer, the dimensionality of the output space\n",
      " |      (i.e. the number of output filters in the convolution).\n",
      " |    kernel_size: An integer or tuple/list of 2 integers, specifying the\n",
      " |      height and width of the 2D convolution window.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |    strides: An integer or tuple/list of 2 integers,\n",
      " |      specifying the strides of the convolution along the height and width.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Specifying any stride value != 1 is incompatible with specifying\n",
      " |      any `dilation_rate` value != 1.\n",
      " |    padding: one of `\"valid\"` or `\"same\"` (case-insensitive).\n",
      " |    data_format: A string,\n",
      " |      one of `channels_last` (default) or `channels_first`.\n",
      " |      The ordering of the dimensions in the inputs.\n",
      " |      `channels_last` corresponds to inputs with shape\n",
      " |      `(batch, height, width, channels)` while `channels_first`\n",
      " |      corresponds to inputs with shape\n",
      " |      `(batch, channels, height, width)`.\n",
      " |      It defaults to the `image_data_format` value found in your\n",
      " |      Keras config file at `~/.keras/keras.json`.\n",
      " |      If you never set it, then it will be \"channels_last\".\n",
      " |    dilation_rate: an integer or tuple/list of 2 integers, specifying\n",
      " |      the dilation rate to use for dilated convolution.\n",
      " |      Can be a single integer to specify the same value for\n",
      " |      all spatial dimensions.\n",
      " |      Currently, specifying any `dilation_rate` value != 1 is\n",
      " |      incompatible with specifying any stride value != 1.\n",
      " |    activation: Activation function to use.\n",
      " |      If you don't specify anything, no activation is applied\n",
      " |      (ie. \"linear\" activation: `a(x) = x`).\n",
      " |    use_bias: Boolean, whether the layer uses a bias vector.\n",
      " |    kernel_initializer: Initializer for the `kernel` weights matrix.\n",
      " |    bias_initializer: Initializer for the bias vector.\n",
      " |    kernel_regularizer: Regularizer function applied to\n",
      " |      the `kernel` weights matrix.\n",
      " |    bias_regularizer: Regularizer function applied to the bias vector.\n",
      " |    activity_regularizer: Regularizer function applied to\n",
      " |      the output of the layer (its \"activation\")..\n",
      " |    kernel_constraint: Constraint function applied to the kernel matrix.\n",
      " |    bias_constraint: Constraint function applied to the bias vector.\n",
      " |  \n",
      " |  Input shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, channels, rows, cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, rows, cols, channels)` if data_format='channels_last'.\n",
      " |  \n",
      " |  Output shape:\n",
      " |    4D tensor with shape:\n",
      " |    `(samples, filters, new_rows, new_cols)` if data_format='channels_first'\n",
      " |    or 4D tensor with shape:\n",
      " |    `(samples, new_rows, new_cols, filters)` if data_format='channels_last'.\n",
      " |    `rows` and `cols` values might have changed due to padding.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Conv2D\n",
      " |      Conv\n",
      " |      tensorflow.python.keras.engine.base_layer.Layer\n",
      " |      tensorflow.python.module.module.Module\n",
      " |      tensorflow.python.training.tracking.tracking.AutoTrackable\n",
      " |      tensorflow.python.training.tracking.base.Trackable\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, filters, kernel_size, strides=(1, 1), padding='valid', data_format=None, dilation_rate=(1, 1), activation=None, use_bias=True, kernel_initializer='glorot_uniform', bias_initializer='zeros', kernel_regularizer=None, bias_regularizer=None, activity_regularizer=None, kernel_constraint=None, bias_constraint=None, **kwargs)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from Conv:\n",
      " |  \n",
      " |  build(self, input_shape)\n",
      " |      Creates the variables of the layer (optional, for subclass implementers).\n",
      " |      \n",
      " |      This is a method that implementers of subclasses of `Layer` or `Model`\n",
      " |      can override if they need a state-creation step in-between\n",
      " |      layer instantiation and layer call.\n",
      " |      \n",
      " |      This is typically used to create the weights of `Layer` subclasses.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        input_shape: Instance of `TensorShape`, or list of instances of\n",
      " |          `TensorShape` if the layer expects a list of inputs\n",
      " |          (one instance per input).\n",
      " |  \n",
      " |  call(self, inputs)\n",
      " |      This is where the layer's logic lives.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Input tensor, or list/tuple of input tensors.\n",
      " |          **kwargs: Additional keyword arguments.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor or list/tuple of tensors.\n",
      " |  \n",
      " |  compute_output_shape(self, input_shape)\n",
      " |      Computes the output shape of the layer.\n",
      " |      \n",
      " |      If the layer has not been built, this method will call `build` on the\n",
      " |      layer. This assumes that the layer will later be used with inputs that\n",
      " |      match the input shape provided here.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          input_shape: Shape tuple (tuple of integers)\n",
      " |              or list of shape tuples (one per output tensor of the layer).\n",
      " |              Shape tuples can include None for free dimensions,\n",
      " |              instead of an integer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An input shape tuple.\n",
      " |  \n",
      " |  get_config(self)\n",
      " |      Returns the config of the layer.\n",
      " |      \n",
      " |      A layer config is a Python dictionary (serializable)\n",
      " |      containing the configuration of a layer.\n",
      " |      The same layer can be reinstantiated later\n",
      " |      (without its trained weights) from this configuration.\n",
      " |      \n",
      " |      The config of a layer does not include connectivity\n",
      " |      information, nor the layer class name. These are handled\n",
      " |      by `Network` (one layer of abstraction above).\n",
      " |      \n",
      " |      Returns:\n",
      " |          Python dictionary.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  __call__(self, inputs, *args, **kwargs)\n",
      " |      Wraps `call`, applying pre- and post-processing steps.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |      \n",
      " |      Note:\n",
      " |        - The following optional keyword arguments are reserved for specific uses:\n",
      " |          * `training`: Boolean scalar tensor of Python boolean indicating\n",
      " |            whether the `call` is meant for training or inference.\n",
      " |          * `mask`: Boolean input mask.\n",
      " |        - If the layer's `call` method takes a `mask` argument (as some Keras\n",
      " |          layers do), its default value will be set to the mask generated\n",
      " |          for `inputs` by the previous layer (if `input` did come from\n",
      " |          a layer that generated a corresponding mask, i.e. if it came from\n",
      " |          a Keras layer with masking support.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: if the layer's `call` method returns None (an invalid value).\n",
      " |  \n",
      " |  __delattr__(self, name)\n",
      " |      Implement delattr(self, name).\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __setattr__(self, name, value)\n",
      " |      Support self.foo = trackable syntax.\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  add_loss(self, losses, inputs=None)\n",
      " |      Add loss tensor(s), potentially dependent on layer inputs.\n",
      " |      \n",
      " |      Some losses (for instance, activity regularization losses) may be dependent\n",
      " |      on the inputs passed when calling a layer. Hence, when reusing the same\n",
      " |      layer on different inputs `a` and `b`, some entries in `layer.losses` may\n",
      " |      be dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      This method can be used inside a subclassed layer or model's `call`\n",
      " |      function, in which case `losses` should be a Tensor or list of Tensors.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      class MyLayer(tf.keras.layers.Layer):\n",
      " |        def call(inputs, self):\n",
      " |          self.add_loss(tf.abs(tf.reduce_mean(inputs)), inputs=True)\n",
      " |          return inputs\n",
      " |      ```\n",
      " |      \n",
      " |      This method can also be called directly on a Functional Model during\n",
      " |      construction. In this case, any loss Tensors passed to this Model must\n",
      " |      be symbolic and be able to be traced back to the model's `Input`s. These\n",
      " |      losses become part of the model's topology and are tracked in `get_config`.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Actvity regularization.\n",
      " |      model.add_loss(tf.abs(tf.reduce_mean(x)))\n",
      " |      ```\n",
      " |      \n",
      " |      If this is not the case for your loss (if, for example, your loss references\n",
      " |      a `Variable` of one of the model's layers), you can wrap your loss in a\n",
      " |      zero-argument lambda. These losses are not tracked as part of the model's\n",
      " |      topology since they can't be serialized.\n",
      " |      \n",
      " |      Example:\n",
      " |      \n",
      " |      ```python\n",
      " |      inputs = tf.keras.Input(shape=(10,))\n",
      " |      x = tf.keras.layers.Dense(10)(inputs)\n",
      " |      outputs = tf.keras.layers.Dense(1)(x)\n",
      " |      model = tf.keras.Model(inputs, outputs)\n",
      " |      # Weight regularization.\n",
      " |      model.add_loss(lambda: tf.reduce_mean(x.kernel))\n",
      " |      ```\n",
      " |      \n",
      " |      The `get_losses_for` method allows to retrieve the losses relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        losses: Loss tensor, or list/tuple of tensors. Rather than tensors, losses\n",
      " |          may also be zero-argument callables which create a loss tensor.\n",
      " |        inputs: Ignored when executing eagerly. If anything other than None is\n",
      " |          passed, it signals the losses are conditional on some of the layer's\n",
      " |          inputs, and thus they should only be run where these inputs are\n",
      " |          available. This is the case for activity regularization losses, for\n",
      " |          instance. If `None` is passed, the losses are assumed\n",
      " |          to be unconditional, and will apply across all dataflows of the layer\n",
      " |          (e.g. weight regularization losses).\n",
      " |  \n",
      " |  add_metric(self, value, aggregation=None, name=None)\n",
      " |      Adds metric tensor to the layer.\n",
      " |      \n",
      " |      Args:\n",
      " |        value: Metric tensor.\n",
      " |        aggregation: Sample-wise metric reduction function. If `aggregation=None`,\n",
      " |          it indicates that the metric tensor provided has been aggregated\n",
      " |          already. eg, `bin_acc = BinaryAccuracy(name='acc')` followed by\n",
      " |          `model.add_metric(bin_acc(y_true, y_pred))`. If aggregation='mean', the\n",
      " |          given metric tensor will be sample-wise reduced using `mean` function.\n",
      " |          eg, `model.add_metric(tf.reduce_sum(outputs), name='output_mean',\n",
      " |          aggregation='mean')`.\n",
      " |        name: String metric name.\n",
      " |      \n",
      " |      Raises:\n",
      " |        ValueError: If `aggregation` is anything other than None or `mean`.\n",
      " |  \n",
      " |  add_update(self, updates, inputs=None)\n",
      " |      Add update op(s), potentially dependent on layer inputs. (deprecated arguments)\n",
      " |      \n",
      " |      Warning: SOME ARGUMENTS ARE DEPRECATED: `(inputs)`. They will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      `inputs` is now automatically inferred\n",
      " |      \n",
      " |      Weight updates (for instance, the updates of the moving mean and variance\n",
      " |      in a BatchNormalization layer) may be dependent on the inputs passed\n",
      " |      when calling a layer. Hence, when reusing the same layer on\n",
      " |      different inputs `a` and `b`, some entries in `layer.updates` may be\n",
      " |      dependent on `a` and some on `b`. This method automatically keeps track\n",
      " |      of dependencies.\n",
      " |      \n",
      " |      The `get_updates_for` method allows to retrieve the updates relevant to a\n",
      " |      specific set of inputs.\n",
      " |      \n",
      " |      This call is ignored when eager execution is enabled (in that case, variable\n",
      " |      updates are run on the fly and thus do not need to be tracked for later\n",
      " |      execution).\n",
      " |      \n",
      " |      Arguments:\n",
      " |        updates: Update op, or list/tuple of update ops, or zero-arg callable\n",
      " |          that returns an update op. A zero-arg callable should be passed in\n",
      " |          order to disable running the updates by setting `trainable=False`\n",
      " |          on this Layer, when executing in Eager mode.\n",
      " |        inputs: Deprecated, will be automatically inferred.\n",
      " |  \n",
      " |  add_variable(self, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! Alias for `add_weight`. (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.add_weight` method instead.\n",
      " |  \n",
      " |  add_weight(self, name=None, shape=None, dtype=None, initializer=None, regularizer=None, trainable=None, constraint=None, partitioner=None, use_resource=None, synchronization=<VariableSynchronization.AUTO: 0>, aggregation=<VariableAggregation.NONE: 0>, **kwargs)\n",
      " |      Adds a new variable to the layer.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        name: Variable name.\n",
      " |        shape: Variable shape. Defaults to scalar if unspecified.\n",
      " |        dtype: The type of the variable. Defaults to `self.dtype` or `float32`.\n",
      " |        initializer: Initializer instance (callable).\n",
      " |        regularizer: Regularizer instance (callable).\n",
      " |        trainable: Boolean, whether the variable should be part of the layer's\n",
      " |          \"trainable_variables\" (e.g. variables, biases)\n",
      " |          or \"non_trainable_variables\" (e.g. BatchNorm mean and variance).\n",
      " |          Note that `trainable` cannot be `True` if `synchronization`\n",
      " |          is set to `ON_READ`.\n",
      " |        constraint: Constraint instance (callable).\n",
      " |        partitioner: Partitioner to be passed to the `Trackable` API.\n",
      " |        use_resource: Whether to use `ResourceVariable`.\n",
      " |        synchronization: Indicates when a distributed a variable will be\n",
      " |          aggregated. Accepted values are constants defined in the class\n",
      " |          `tf.VariableSynchronization`. By default the synchronization is set to\n",
      " |          `AUTO` and the current `DistributionStrategy` chooses\n",
      " |          when to synchronize. If `synchronization` is set to `ON_READ`,\n",
      " |          `trainable` must not be set to `True`.\n",
      " |        aggregation: Indicates how a distributed variable will be aggregated.\n",
      " |          Accepted values are constants defined in the class\n",
      " |          `tf.VariableAggregation`.\n",
      " |        **kwargs: Additional keyword arguments. Accepted values are `getter`,\n",
      " |          `collections`, `experimental_autocast` and `caching_device`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The created variable. Usually either a `Variable` or `ResourceVariable`\n",
      " |        instance. If `partitioner` is not `None`, a `PartitionedVariable`\n",
      " |        instance is returned.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called with partitioned variable regularization and\n",
      " |          eager execution is enabled.\n",
      " |        ValueError: When giving unsupported dtype and no initializer or when\n",
      " |          trainable has been set to True with synchronization set as `ON_READ`.\n",
      " |  \n",
      " |  apply(self, inputs, *args, **kwargs)\n",
      " |      Deprecated, do NOT use! (deprecated)\n",
      " |      \n",
      " |      Warning: THIS FUNCTION IS DEPRECATED. It will be removed in a future version.\n",
      " |      Instructions for updating:\n",
      " |      Please use `layer.__call__` method instead.\n",
      " |      \n",
      " |      This is an alias of `self.__call__`.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor(s).\n",
      " |        *args: additional positional arguments to be passed to `self.call`.\n",
      " |        **kwargs: additional keyword arguments to be passed to `self.call`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor(s).\n",
      " |  \n",
      " |  compute_mask(self, inputs, mask=None)\n",
      " |      Computes an output mask tensor.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          inputs: Tensor or list of tensors.\n",
      " |          mask: Tensor or list of tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |          None or a tensor (or list of tensors,\n",
      " |              one per output tensor of the layer).\n",
      " |  \n",
      " |  compute_output_signature(self, input_signature)\n",
      " |      Compute the output tensor signature of the layer based on the inputs.\n",
      " |      \n",
      " |      Unlike a TensorShape object, a TensorSpec object contains both shape\n",
      " |      and dtype information for a tensor. This method allows layers to provide\n",
      " |      output dtype information if it is different from the input dtype.\n",
      " |      For any layer that doesn't implement this function,\n",
      " |      the framework will fall back to use `compute_output_shape`, and will\n",
      " |      assume that the output dtype matches the input dtype.\n",
      " |      \n",
      " |      Args:\n",
      " |        input_signature: Single TensorSpec or nested structure of TensorSpec\n",
      " |          objects, describing a candidate input for the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Single TensorSpec or nested structure of TensorSpec objects, describing\n",
      " |          how the layer would transform the provided input.\n",
      " |      \n",
      " |      Raises:\n",
      " |        TypeError: If input_signature contains a non-TensorSpec object.\n",
      " |  \n",
      " |  count_params(self)\n",
      " |      Count the total number of scalars composing the weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |          An integer count.\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: if the layer isn't yet built\n",
      " |            (in which case its weights aren't yet defined).\n",
      " |  \n",
      " |  get_input_at(self, node_index)\n",
      " |      Retrieves the input tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_input_mask_at(self, node_index)\n",
      " |      Retrieves the input mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple inputs).\n",
      " |  \n",
      " |  get_input_shape_at(self, node_index)\n",
      " |      Retrieves the input shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple inputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_losses_for(self, inputs)\n",
      " |      Retrieves losses relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of loss tensors of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_output_at(self, node_index)\n",
      " |      Retrieves the output tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A tensor (or list of tensors if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_output_mask_at(self, node_index)\n",
      " |      Retrieves the output mask tensor(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A mask tensor\n",
      " |          (or list of tensors if the layer has multiple outputs).\n",
      " |  \n",
      " |  get_output_shape_at(self, node_index)\n",
      " |      Retrieves the output shape(s) of a layer at a given node.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          node_index: Integer, index of the node\n",
      " |              from which to retrieve the attribute.\n",
      " |              E.g. `node_index=0` will correspond to the\n",
      " |              first time the layer was called.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A shape tuple\n",
      " |          (or list of shape tuples if the layer has multiple outputs).\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |  \n",
      " |  get_updates_for(self, inputs)\n",
      " |      Retrieves updates relevant to a specific set of inputs.\n",
      " |      \n",
      " |      Arguments:\n",
      " |        inputs: Input tensor or list/tuple of input tensors.\n",
      " |      \n",
      " |      Returns:\n",
      " |        List of update ops of the layer that depend on `inputs`.\n",
      " |  \n",
      " |  get_weights(self)\n",
      " |      Returns the current weights of the layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Weights values as a list of numpy arrays.\n",
      " |  \n",
      " |  set_weights(self, weights)\n",
      " |      Sets the weights of the layer, from Numpy arrays.\n",
      " |      \n",
      " |      Arguments:\n",
      " |          weights: a list of Numpy arrays. The number\n",
      " |              of arrays and their shape must match\n",
      " |              number of the dimensions of the weights\n",
      " |              of the layer (i.e. it should match the\n",
      " |              output of `get_weights`).\n",
      " |      \n",
      " |      Raises:\n",
      " |          ValueError: If the provided weights list does not match the\n",
      " |              layer's specifications.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  from_config(config) from builtins.type\n",
      " |      Creates a layer from its config.\n",
      " |      \n",
      " |      This method is the reverse of `get_config`,\n",
      " |      capable of instantiating the same layer from the config\n",
      " |      dictionary. It does not handle layer connectivity\n",
      " |      (handled by Network), nor weights (handled by `set_weights`).\n",
      " |      \n",
      " |      Arguments:\n",
      " |          config: A Python dictionary, typically the\n",
      " |              output of get_config.\n",
      " |      \n",
      " |      Returns:\n",
      " |          A layer instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.keras.engine.base_layer.Layer:\n",
      " |  \n",
      " |  activity_regularizer\n",
      " |      Optional regularizer function for the output of this layer.\n",
      " |  \n",
      " |  dtype\n",
      " |  \n",
      " |  dynamic\n",
      " |  \n",
      " |  inbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  input\n",
      " |      Retrieves the input tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input tensor or list of input tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        RuntimeError: If called in Eager mode.\n",
      " |        AttributeError: If no inbound nodes are found.\n",
      " |  \n",
      " |  input_mask\n",
      " |      Retrieves the input mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input mask tensor (potentially None) or list of input\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  input_shape\n",
      " |      Retrieves the input shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one input,\n",
      " |      i.e. if it is connected to one incoming layer, or if all inputs\n",
      " |      have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Input shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per input tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined input_shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  input_spec\n",
      " |  \n",
      " |  losses\n",
      " |      Losses which are associated with this `Layer`.\n",
      " |      \n",
      " |      Variable regularization tensors are created when this property is accessed,\n",
      " |      so it is eager safe: accessing `losses` under a `tf.GradientTape` will\n",
      " |      propagate gradients back to the corresponding variables.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of tensors.\n",
      " |  \n",
      " |  metrics\n",
      " |  \n",
      " |  name\n",
      " |      Returns the name of this module as passed or determined in the ctor.\n",
      " |      \n",
      " |      NOTE: This is not the same as the `self.name_scope.name` which includes\n",
      " |      parent module names.\n",
      " |  \n",
      " |  non_trainable_variables\n",
      " |  \n",
      " |  non_trainable_weights\n",
      " |  \n",
      " |  outbound_nodes\n",
      " |      Deprecated, do NOT use! Only for compatibility with external Keras.\n",
      " |  \n",
      " |  output\n",
      " |      Retrieves the output tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one output,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |        Output tensor or list of output tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |        AttributeError: if the layer is connected to more than one incoming\n",
      " |          layers.\n",
      " |        RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  output_mask\n",
      " |      Retrieves the output mask tensor(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has exactly one inbound node,\n",
      " |      i.e. if it is connected to one incoming layer.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output mask tensor (potentially None) or list of output\n",
      " |          mask tensors.\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer is connected to\n",
      " |          more than one incoming layers.\n",
      " |  \n",
      " |  output_shape\n",
      " |      Retrieves the output shape(s) of a layer.\n",
      " |      \n",
      " |      Only applicable if the layer has one output,\n",
      " |      or if all outputs have the same shape.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Output shape, as an integer shape tuple\n",
      " |          (or list of shape tuples, one tuple per output tensor).\n",
      " |      \n",
      " |      Raises:\n",
      " |          AttributeError: if the layer has no defined output shape.\n",
      " |          RuntimeError: if called in Eager mode.\n",
      " |  \n",
      " |  stateful\n",
      " |  \n",
      " |  trainable\n",
      " |  \n",
      " |  trainable_variables\n",
      " |      Sequence of trainable variables owned by this module and its submodules.\n",
      " |      \n",
      " |      Note: this method uses reflection to find variables on the current instance\n",
      " |      and submodules. For performance reasons you may wish to cache the result\n",
      " |      of calling this method if you don't expect the return value to change.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of variables for the current module (sorted by attribute\n",
      " |        name) followed by variables from all submodules recursively (breadth\n",
      " |        first).\n",
      " |  \n",
      " |  trainable_weights\n",
      " |  \n",
      " |  updates\n",
      " |  \n",
      " |  variables\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Alias of `self.weights`.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  weights\n",
      " |      Returns the list of all layer variables/weights.\n",
      " |      \n",
      " |      Returns:\n",
      " |        A list of variables.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  with_name_scope(method) from builtins.type\n",
      " |      Decorator to automatically enter the module name scope.\n",
      " |      \n",
      " |      ```\n",
      " |      class MyModule(tf.Module):\n",
      " |        @tf.Module.with_name_scope\n",
      " |        def __call__(self, x):\n",
      " |          if not hasattr(self, 'w'):\n",
      " |            self.w = tf.Variable(tf.random.normal([x.shape[1], 64]))\n",
      " |          return tf.matmul(x, self.w)\n",
      " |      ```\n",
      " |      \n",
      " |      Using the above module would produce `tf.Variable`s and `tf.Tensor`s whose\n",
      " |      names included the module name:\n",
      " |      \n",
      " |      ```\n",
      " |      mod = MyModule()\n",
      " |      mod(tf.ones([8, 32]))\n",
      " |      # ==> <tf.Tensor: ...>\n",
      " |      mod.w\n",
      " |      # ==> <tf.Variable ...'my_module/w:0'>\n",
      " |      ```\n",
      " |      \n",
      " |      Args:\n",
      " |        method: The method to wrap.\n",
      " |      \n",
      " |      Returns:\n",
      " |        The original method wrapped such that it enters the module's name scope.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.module.module.Module:\n",
      " |  \n",
      " |  name_scope\n",
      " |      Returns a `tf.name_scope` instance for this class.\n",
      " |  \n",
      " |  submodules\n",
      " |      Sequence of all sub-modules.\n",
      " |      \n",
      " |      Submodules are modules which are properties of this module, or found as\n",
      " |      properties of modules which are properties of this module (and so on).\n",
      " |      \n",
      " |      ```\n",
      " |      a = tf.Module()\n",
      " |      b = tf.Module()\n",
      " |      c = tf.Module()\n",
      " |      a.b = b\n",
      " |      b.c = c\n",
      " |      assert list(a.submodules) == [b, c]\n",
      " |      assert list(b.submodules) == [c]\n",
      " |      assert list(c.submodules) == []\n",
      " |      ```\n",
      " |      \n",
      " |      Returns:\n",
      " |        A sequence of all submodules.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from tensorflow.python.training.tracking.base.Trackable:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(tf.keras.layers.Conv2D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Flatten(input_shape=(28,28)))    # keras processing layer - no neurons\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 784]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-b32607af3871>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m model.add(tf.keras.layers.Conv2D(filters=conv1_feature_maps, kernel_size=conv1_kernel_size,\n\u001b[0;32m      3\u001b[0m                       \u001b[0mstrides\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv1_stride\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconv1_pad\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                       activation=tf.nn.relu, name='conv1'))\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf37\\lib\\site-packages\\tensorflow_core\\python\\training\\tracking\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tf37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    201\u001b[0m       \u001b[1;31m# If the model is being built continuously on top of an input layer:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    202\u001b[0m       \u001b[1;31m# refresh its output.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 203\u001b[1;33m       \u001b[0moutput_tensor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    204\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    205\u001b[0m         raise TypeError('All layers in a Sequential model '\n",
      "\u001b[1;32m~\\.conda\\envs\\tf37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    735\u001b[0m         \u001b[1;31m# are casted, not before.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    736\u001b[0m         input_spec.assert_input_compatibility(self.input_spec, inputs,\n\u001b[1;32m--> 737\u001b[1;33m                                               self.name)\n\u001b[0m\u001b[0;32m    738\u001b[0m         if (any(isinstance(x, ragged_tensor.RaggedTensor) for x in input_list)\n\u001b[0;32m    739\u001b[0m             and self._supports_ragged_inputs is False):  # pylint: disable=g-bool-id-comparison\n",
      "\u001b[1;32m~\\.conda\\envs\\tf37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    175\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    176\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 177\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    178\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    179\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv1 is incompatible with the layer: expected ndim=4, found ndim=2. Full shape received: [None, 784]"
     ]
    }
   ],
   "source": [
    "#no need to pass in X yet\n",
    "#need input as hieght x width x channels\n",
    "model.add(tf.keras.layers.Conv2D(filters=conv1_feature_maps, kernel_size=conv1_kernel_size,\n",
    "                      strides=conv1_stride, padding=conv1_pad, \n",
    "                      activation=tf.nn.relu, name='conv1'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(tf.keras.layers.Conv2D(filters=conv2_feature_maps,\n",
    "                                 kernel_size=conv2_kernel_size,\n",
    "                                 strides=conv2_stride, padding=conv2_pad,\n",
    "                                 activation=tf.nn.relu, name='conv2'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tensorflow.python.keras.layers.convolutional.Conv2D at 0x23529759548>]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-46-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tf37\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msummary\u001b[1;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[0;32m   1300\u001b[0m     \"\"\"\n\u001b[0;32m   1301\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1302\u001b[1;33m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[0;32m   1303\u001b[0m                        \u001b[1;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m                        \u001b[1;34m'`fit()` with some data, or specify '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "#do this later\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
